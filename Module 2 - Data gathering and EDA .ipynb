{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from selenium import webdriver\n",
    "#Define the webdriver \n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import requests #to retrieve HTML and transfer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: use setter for headless property instead of set_headless\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "opts = Options()\n",
    "opts.set_headless()\n",
    "assert opts.headless # Operating in headless mode\n",
    "\n",
    "#Insert link for scraping\n",
    "browser = Chrome(options=opts)\n",
    "browser.get('https://forum.flowster.app/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get Category and Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Topics\n",
      "Amazon Specific\n",
      "Have questions about using the Amazon marketplace? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "All Other Amazon Related Issues\n",
      "Software & Tools\n",
      "PPC\n",
      "Reviews & Customer Service\n",
      "Inventory Management\n",
      "Pricing Management\n",
      "Product Prep\n",
      "59\n",
      "Flowster-specific\n",
      "Discussion about Flowster, this Forum’s organization, and how we can improve it.\n",
      "Updates\n",
      "Free SOPs\n",
      "Marketplace\n",
      "61\n",
      "Store & Website Management\n",
      "Have questions about Store & Website Management? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Product Detail Pages\n",
      "Copywriting\n",
      "Video & Photography\n",
      "Branding\n",
      "Payments & Fraud\n",
      "2\n",
      "Product Sourcing\n",
      "Have questions about sourcing products? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Purchasing\n",
      "Sourcing Brand Name Products\n",
      "Vendor Management\n",
      "Pricing & Negotiation\n",
      "Vendor Relations\n",
      "Product Creation\n",
      "57\n",
      "Management\n",
      "Have questions about Management? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Leadership\n",
      "Delegation\n",
      "14\n",
      "Fulfillment\n",
      "Have questions about Fulfillment? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Shipping\n",
      "Third Party Fulfillment\n",
      "Warehouse Management\n",
      "17\n",
      "eCommerce Marketplaces\n",
      "Have questions about sourcing the various sales channels available to you? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Amazon\n",
      "eBay\n",
      "Walmart\n",
      "Jet\n",
      "All Other Sales Channels\n",
      "2\n",
      "Traffic Sources\n",
      "Have questions about generating traffic? Please be sure to select the most appropriate sub-category for your questions.\n",
      "Email Marketing\n",
      "PPC\n",
      "YouTube\n",
      "All Other Traffic Sources\n",
      "Facebook\n",
      "Facebook Messenger\n",
      "Google\n",
      "Instragram\n",
      "SEO\n",
      "Blogging & Content Marketing\n",
      "Kickstarter and Crowdfunding\n",
      "7\n",
      "Software & Tools\n",
      "Have questions about Software & Tools? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Shopify\n",
      "Project Management\n",
      "Standard Operating Procedures\n",
      "SaaS Applications\n",
      "14\n",
      "Financial Management\n",
      "Have questions about Financial Management? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Accounting & Bookkeeping\n",
      "Fundraising\n",
      "7\n",
      "Human Resources\n",
      "Have questions about Human Resources? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Performance Reviews\n",
      "Recruiting\n",
      "Outsourcing\n",
      "Managing a Virtual Team\n",
      "Employee Onboarding\n",
      "Employee Termination\n",
      "20\n",
      "Misc Topics\n",
      "Have questions about things that don’t fall under the other categories? This is the category to use. Please be sure to select the most appropriate sub-category for your questions.\n",
      "Networking & Events\n",
      "Education & Training\n",
      "Buying or Selling a Business\n",
      "Member Introductions\n",
      "Articles, Books, and Resources\n",
      "Product Launches\n",
      "Competitor Analysis\n",
      "Buy, Sell, and Trade Stuff\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "category_table = browser.find_elements_by_class_name('category-list')\n",
    "print(category_table[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flowster-specific'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = browser.find_elements_by_class_name('category-text-title')\n",
    "categories[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://forum.flowster.app/c/store-website-management/40'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_links = browser.find_elements_by_css_selector('.category > h3 > a')\n",
    "categ_links[2].get_attribute('href')\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of catergories\n",
    "len(categ_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_names = []\n",
    "categ_urls = []\n",
    "for categ, link in zip(categories, categ_links):\n",
    "    categ_names.append(categ.text)\n",
    "    categ_urls.append(link.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Amazon Specific',\n",
       "  'Flowster-specific',\n",
       "  'Store & Website Management',\n",
       "  'Product Sourcing',\n",
       "  'Management',\n",
       "  'Fulfillment',\n",
       "  'eCommerce Marketplaces',\n",
       "  'Traffic Sources',\n",
       "  'Software & Tools',\n",
       "  'Financial Management',\n",
       "  'Human Resources',\n",
       "  'Misc Topics'],\n",
       " ['https://forum.flowster.app/c/amazon-specific/17',\n",
       "  'https://forum.flowster.app/c/flowster/2',\n",
       "  'https://forum.flowster.app/c/store-website-management/40',\n",
       "  'https://forum.flowster.app/c/product-sourcing/8',\n",
       "  'https://forum.flowster.app/c/management/32',\n",
       "  'https://forum.flowster.app/c/fulfillment/36',\n",
       "  'https://forum.flowster.app/c/sales-channels/7',\n",
       "  'https://forum.flowster.app/c/traffic/13',\n",
       "  'https://forum.flowster.app/c/software-tools/26',\n",
       "  'https://forum.flowster.app/c/financial-management/21',\n",
       "  'https://forum.flowster.app/c/human-resources/46',\n",
       "  'https://forum.flowster.app/c/misc-topics/55'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_names, categ_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access category by using url\n",
    "\n",
    "\n",
    "CATEG_URL = categ_links[2].get_attribute('href')\n",
    "#page = requests.get(SEC_URL)\n",
    "browser.get(CATEG_URL)\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(3)\n",
    "#print(browser.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get page content\n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeWebM_topics_links = soup.find_all('a', class_='title raw-link raw-topic-link')\n",
    "len(storeWebM_topics_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/t/about-the-store-website-management-category/58'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeWebM_topics_links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://forum.flowster.app/t/about-the-store-website-management-category/58',\n",
       " 'https://forum.flowster.app/t/securing-long-term-partnerships/1545',\n",
       " 'https://forum.flowster.app/t/amazon-free-products/1470']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeWebM_topics_urls =[]\n",
    "\n",
    "BASE_URL = 'https://forum.flowster.app'\n",
    "for topic_link in storeWebM_topics_links:\n",
    "    storeWebM_topics_urls.append(BASE_URL + topic_link['href'])\n",
    "    \n",
    "storeWebM_topics_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title = soup.find_all('a', class_='title raw-link raw-topic-link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['About the Store & Website Management category',\n",
       " 'Securing long term partnerships',\n",
       " 'Amazon Free Products']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_titles = []\n",
    "\n",
    "for title in topic_title:\n",
    "    topic_titles.append(title.text)\n",
    "    \n",
    "topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get topic post, like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondtopic_url = storeWebM_topics_urls[1]\n",
    "#page = requests.get(SEC_URL)\n",
    "browser.get(secondtopic_url)\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondtopic_soup = BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all posts\n",
    "postStream = secondtopic_soup.find('div', class_='post-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get post and post's replies then extract\n",
    "postDivs = postStream.find_all('div', {'class': ['topic-post clearfix topic-owner regular', 'topic-post clearfix regular']})\n",
    "#????????#\n",
    "\n",
    "comments = []\n",
    "for i in range(len(postDivs)):\n",
    "    comment = postDivs[i].find('div', class_='cooked').text\n",
    "    comments.append(comment)\n",
    "    \n",
    "leading_comment = comments[0]\n",
    "\n",
    "if len(comments) == 1:\n",
    "    other_comments = ('no other comment')\n",
    "else:\n",
    "    other_comments = comments[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I just closed a deal to manage a quite large brand account on Amazon, my main concern now is that this partnership may only last 1-2 years and once the account has grown to higher levels they would just manage it by themselves. What methods, tips and tricks you can suggest to protect this deal and make sure they will stick with my company managing their account for long term? Essentially how can I make them dependent on me so it will be very hard for them to let go our partnership?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brand management is going to have partner turnover.  There will always be high expectations and, even if you raise sales 20%, they’ll want a 30% increase the next quarter.  I think one good tip is to set reasonable expectations.  Let them know all the activities you will undertake and don’t over-promise a sales increase.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec 5, 2020 5:49 pm'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created = postStream.find('li', class_= \"created-at\")\n",
    "created_at = created.find('span', class_= 'relative-date')\n",
    "created_at['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec 7, 2020 3:02 pm'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_reply = postStream.find('li', class_= \"last-reply\")\n",
    "last_reply_at = last_reply.find('span', class_= 'relative-date')['title']\n",
    "last_reply_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies = postStream.find('li', class_=\"replies\")\n",
    "nbr_replies = replies.find('span', class_='number').text\n",
    "nbr_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'115'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views = postStream.find('li', class_=\"secondary views\")\n",
    "nbr_views = views.find('span', class_='number').text\n",
    "nbr_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scraper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from os.path import expanduser\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper:\n",
    "    browser = None\n",
    "    topic_dict = {}\n",
    "    topic_df = pd.DataFrame(columns = [\n",
    "        'topic title',\n",
    "        'category',\n",
    "        'tags',\n",
    "        'leading post', \n",
    "        'post replies',\n",
    "        'created_at', \n",
    "        'like',\n",
    "        'view',\n",
    "        'replies',\n",
    "    ])\n",
    "    def __init__(self, webdriverpath): #2 underscores\n",
    "        opts = Options()\n",
    "        opts.set_headless()\n",
    "        assert opts.headless\n",
    "        self.browser = Chrome(options=opts, executable_path=webdriverpath)\n",
    "        \n",
    "    def get_topic(self, topic_soup):\n",
    "        \n",
    "        topic_titles = topic_soup.find_all('a', class_='title raw-link raw-topic-link')\n",
    "        topic_title = []\n",
    "        for title in topic_titles:\n",
    "            topic_title.append(title.text)\n",
    "            \n",
    "        \n",
    "        topic_wrapper = topic_soup.find('div', class_ = 'title-wrapper')\n",
    "        topic_tag = topic_wrapper.find_all('span', class_='category-name')\n",
    "        topic_tag = [tag.text for tag in topic_tag]\n",
    "        try:\n",
    "            topic_category = topic_tag[0]\n",
    "            if len(topic_tag)==1:\n",
    "                topic_tag = ('no more topic tag')\n",
    "            else:\n",
    "                topic_tag = topics_tag[1:]\n",
    "        except: #????????#\n",
    "            topic_category = ''\n",
    "            topic_tag = ''\n",
    "        \n",
    "        return topic_title, topic_category, topic_tag\n",
    "    \n",
    "    \n",
    "    def get_topic_comment(self, topic_soup):\n",
    "        postStream = topic_soup.find('div', class_='post-stream')\n",
    "        postsDivs = postStream.find_all('div', {'class': ['topic-post clearfix topic-owner regular', 'topic-post clearfix regular']})\n",
    "\n",
    "        comments = []\n",
    "        for i in range(len(postsDivs)):\n",
    "            comment = postsDivs[i].find('div', class_='cooked').text\n",
    "            comments.append(comment)\n",
    "        try:\n",
    "            leading_comment = comments[0]\n",
    "            if len(comments) == 1:\n",
    "                other_comments = ('no more comment')\n",
    "            else:\n",
    "                other_comments = comments[1:]\n",
    "        except:\n",
    "            leading_comment, other_comments = [], []\n",
    "        \n",
    "        return leading_comment, other_comments\n",
    "    \n",
    "    \n",
    "    def get_topic_created_at(self, topic_soup):\n",
    "        created = topic_soup.find('li', class_=\"created-at\")\n",
    "        \n",
    "        if created is None:\n",
    "            created_at = str(0)\n",
    "        else:\n",
    "            created_at = created.find('span', class_='relative-date')['title']\n",
    "    \n",
    "        return created_at\n",
    "    \n",
    "    \n",
    "    def get_topic_replies_nbr(self, topic_soup):\n",
    "        replies = topic_soup.find('li', class_=\"replies\")\n",
    "        \n",
    "        if replies == None:\n",
    "            nbr_replies = str(0)\n",
    "        else:\n",
    "            nbr_replies = replies.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_replies\n",
    "\n",
    "    \n",
    "    def get_topic_views_nbr(self, topic_soup):\n",
    "        views = topic_soup.find('li', class_=\"secondary views\")\n",
    "        \n",
    "        if views is None:\n",
    "            nbr_views = str(0)\n",
    "        else:\n",
    "            nbr_views = views.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_views\n",
    "\n",
    "    \n",
    "    def get_topic_likes_nbr(self, topic_soup):\n",
    "        likes = topic_soup.find('li', class_=\"secondary likes\")\n",
    "        \n",
    "        if likes is None:\n",
    "            nbr_likes = str(0)\n",
    "        else:\n",
    "            nbr_likes = likes.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_likes\n",
    "    \n",
    "    \n",
    "    def Scraper(self, base_url, site_name):\n",
    "        \n",
    "        #1. Retrieve page source in browser\n",
    "        self.browser.get(base_url)\n",
    "        \n",
    "        #2. Get all category link\n",
    "        categ_links = self.browser.find_elements_by_css_selector('.category > h3 > a')\n",
    "        categ_urls = []\n",
    "        for link in categ_links:\n",
    "            categ_urls.append(link.get_attribute('href'))\n",
    "        \n",
    "        for categ_url in categ_urls:\n",
    "            self.browser.get(categ_url)\n",
    "        \n",
    "            #??????????#\n",
    "            # Load the entire webage by scrolling to the bottom\n",
    "            lastHeight = self.browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "            \n",
    "            while (True):\n",
    "                # Scroll to bottom of page\n",
    "                self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait for new page segment to load\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                newHeight = self.browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                if newHeight == lastHeight:\n",
    "                    break\n",
    "                    \n",
    "                lastHeight = newHeight\n",
    "            #4. Create category soup\n",
    "            categoryHTML = self.browser.page_source\n",
    "            categ_topic_soup = BeautifulSoup(categoryHTML, 'html.parser')\n",
    "    \n",
    "            categ_topic_links = categ_topic_soup.find_all('a', class_='title raw-link raw-topic-link')\n",
    "    \n",
    "            # Get all the topic urls \n",
    "            categ_topic_urls = []\n",
    "            for topic_link in categ_topic_links:\n",
    "                categ_topic_urls.append(base_url + topic_link['href'])\n",
    "                \n",
    "            for categ_topic_url in categ_topic_urls:\n",
    "                # Get current topic_soup\n",
    "                self.browser.get(categ_topic_url)\n",
    "                topicHTML = self.browser.page_source\n",
    "                topic_soup = BeautifulSoup(topicHTML, 'html.parser')\n",
    "                \n",
    "                # Scrape all topic attributes of interest\n",
    "                topic_title, topic_category, topic_tag = self.get_topic(topic_soup)\n",
    "                leading_comment, other_comments = self.get_topic_comment(topic_soup)\n",
    "                created_at = self.get_topic_created_at(topic_soup)\n",
    "                nbr_replies = self.get_topic_replies_nbr(topic_soup)\n",
    "                nbr_views = self.get_topic_views_nbr(topic_soup)\n",
    "                nbr_likes = self.get_topic_likes_nbr(topic_soup)\n",
    "                \n",
    "                #Add to dictionary\n",
    "                attribute_dict = {\n",
    "                    'topic title': topic_title,\n",
    "                    'category': topic_category,\n",
    "                    'tags': topic_tag,\n",
    "                    'leading post': leading_comment, \n",
    "                    'post replies': other_comments,\n",
    "                    'created_at': created_at, \n",
    "                    'like': nbr_likes,\n",
    "                    'view': nbr_views,\n",
    "                    'replies': nbr_replies}\n",
    "                \n",
    "                #self.topic_dict[topic_title] = attribute_dict\n",
    "                self.topic_dict = attribute_dict\n",
    "                self.topic_df = self.topic_df.append(attribute_dict, ignore_index = True)\n",
    "                \n",
    "                #test\n",
    "                #print('Title :', topic_title)\n",
    "                #print('Category :', topic_category)\n",
    "                #print('URL :', categ_topic_url)\n",
    "                \n",
    "        #timestamp\n",
    "        timeStamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        \n",
    "        #4. Save data in json and csv\n",
    "        #jsonFilename = site_name + '_SCRAPED_DATA_' + timeStamp + '.json'\n",
    "        csvFilename = site_name + '_SCRAPED_DATA_' + timeStamp + '.csv'\n",
    "        \n",
    "        #jsonFileFullPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), jsonFilename)\n",
    "        csvFileFullPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), csvFilename)\n",
    "        \n",
    "        #userhome = expanduser(\"~\")\n",
    "        #csvFileFullPath = os.path.join(userhome, 'Desktop', csvFilename)\n",
    "        #open(csvFileFullPath, \"r\")\n",
    "        \n",
    "        # Save scraped data  into json file\n",
    "        #with open(jsonFileFullPath, 'w') as f:\n",
    "            #json.dump(self.topic_dict, f)\n",
    "        \n",
    "        # Save dataframe into csv file\n",
    "        self.topic_df.to_csv(csvFileFullPath)\n",
    "        \n",
    "        #final = self.topic_df\n",
    "        \n",
    "        #return(final)\n",
    "        #print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: use setter for headless property instead of set_headless\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f50bff959ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Run the webscraper and save scraped data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mwebScraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-ce6f7673bb61>\u001b[0m in \u001b[0;36mScraper\u001b[0;34m(self, base_url, site_name)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m#jsonFileFullPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), jsonFilename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mcsvFileFullPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsvFilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m#userhome = expanduser(\"~\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Local path to webdriver \n",
    "    webdriverpath = '/usr/local/bin/chromedriver'\n",
    "    ##terminal: which chromedriver\n",
    "    ##rm restrict: xattr -d com.apple.quarantine /usr/local/bin/chromedriver\n",
    "    \n",
    "    \n",
    "    # Forum to scrape URL    \n",
    "    base_url= 'https://forum.flowster.app'\n",
    "    \n",
    "    # Name of the forum\n",
    "    site_name = 'FLOWSTER'\n",
    "        \n",
    "    # WebScraping object\n",
    "    webScraper = WebScraper(webdriverpath)\n",
    "    \n",
    "    # Run the webscraper and save scraped data\n",
    "    webScraper.Scraper(base_url, site_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re #for regular expressions\n",
    "import string #for handling string\n",
    "import math # for mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://raw.githubusercontent.com/mentorchains/level1_post_recommender_20/md2/webScraping_EDA_tutorials/FLOWSTER_SCRAPED_DATA20201212224954.csv'\n",
    "data = pd.read_csv(url,index_col=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Leading Post</th>\n",
       "      <th>Post Replies</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Views</th>\n",
       "      <th>Replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>About the Store &amp; Website Management category</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have questions about Store &amp; Website Managemen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Securing long term partnerships</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello, I just closed a deal to manage a quite ...</td>\n",
       "      <td>['Brand management is going to have partner tu...</td>\n",
       "      <td>Dec 5, 2020 5:49 pm</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Amazon Free Products</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello,\\nI need some buyers for my products in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>About the Product Sourcing Category</td>\n",
       "      <td>Product Sourcing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have questions about sourcing products? This i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Virtual Assistant sending Emails Hubspot</td>\n",
       "      <td>Product Sourcing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello Bright Ideas Tribe,\\nI would like to giv...</td>\n",
       "      <td>['\\n\\n\\nknowledge.hubspot.com 1\\n\\n\\n\\nCreate ...</td>\n",
       "      <td>Nov 18, 2020 9:12 pm</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Topic Title                    Category  \\\n",
       "0  About the Store & Website Management category  Store & Website Management   \n",
       "1                Securing long term partnerships  Store & Website Management   \n",
       "2                           Amazon Free Products  Store & Website Management   \n",
       "3            About the Product Sourcing Category            Product Sourcing   \n",
       "4       Virtual Assistant sending Emails Hubspot            Product Sourcing   \n",
       "\n",
       "  Tags                                       Leading Post  \\\n",
       "0   []  Have questions about Store & Website Managemen...   \n",
       "1   []  Hello, I just closed a deal to manage a quite ...   \n",
       "2   []  Hello,\\nI need some buyers for my products in ...   \n",
       "3   []  Have questions about sourcing products? This i...   \n",
       "4   []  Hello Bright Ideas Tribe,\\nI would like to giv...   \n",
       "\n",
       "                                        Post Replies            Created_at  \\\n",
       "0                                                 []                     0   \n",
       "1  ['Brand management is going to have partner tu...   Dec 5, 2020 5:49 pm   \n",
       "2                                                 []                     0   \n",
       "3                                                 []                     0   \n",
       "4  ['\\n\\n\\nknowledge.hubspot.com 1\\n\\n\\n\\nCreate ...  Nov 18, 2020 9:12 pm   \n",
       "\n",
       "   Likes  Views  Replies  \n",
       "0      0      0        0  \n",
       "1      0     19        1  \n",
       "2      0      0        0  \n",
       "3      0      0        0  \n",
       "4      0     81        5  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 278 entries, 0 to 277\n",
      "Data columns (total 9 columns):\n",
      "Topic Title     278 non-null object\n",
      "Category        278 non-null object\n",
      "Tags            278 non-null object\n",
      "Leading Post    277 non-null object\n",
      "Post Replies    278 non-null object\n",
      "Created_at      278 non-null object\n",
      "Likes           278 non-null int64\n",
      "Views           278 non-null int64\n",
      "Replies         278 non-null int64\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 21.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I just closed a deal to manage a quite large brand account on Amazon, my main concern now is that this partnership may only last 1-2 years and once the account has grown to higher levels they would just manage it by themselves. What methods, tips and tricks you can suggest to protect this deal and make sure they will stick with my company managing their account for long term? Essentially how can I make them dependent on me so it will be very hard for them to let go our partnership?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Leading Post'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
